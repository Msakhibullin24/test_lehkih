"""
–û–±—É—á–µ–Ω–∏–µ 3D U-Net –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —É–∑–µ–ª–∫–æ–≤ –≤ –ª—ë–≥–∫–∏—Ö (LUNA16).
–ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ CUDA ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ subset* –ø–∞–ø–∫–∏ –∏–∑ data/.

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:
    LUNA16_Project/
    ‚îú‚îÄ‚îÄ data/              ‚Üê subset0..subset6 –≤–Ω—É—Ç—Ä–∏
    ‚îú‚îÄ‚îÄ masks/             ‚Üê –º–∞—Å–∫–∏ (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç prepare_masks.py)
    ‚îú‚îÄ‚îÄ seg-lungs/         ‚Üê –º–∞—Å–∫–∏ –ª—ë–≥–∫–∏—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    ‚îú‚îÄ‚îÄ annotations.csv
    ‚îú‚îÄ‚îÄ candidates.csv
    ‚îú‚îÄ‚îÄ prepare_masks.py
    ‚îî‚îÄ‚îÄ train.py           ‚Üê –≠–¢–û–¢ –§–ê–ô–õ
"""

import os
import glob
import time
import torch
import torch.nn as nn
import numpy as np
from tqdm import tqdm
from monai.transforms import (
    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityRanged,
    Spacingd, SpatialPadd, RandCropByPosNegLabeld, RandFlipd, RandRotate90d,
    RandGaussianNoised, RandScaleIntensityd, RandShiftIntensityd,
)
import SimpleITK as sitk
import itk  # noqa: F401 ‚Äî –Ω—É–∂–µ–Ω –¥–ª—è MONAI ITKReader
from monai.data import CacheDataset, DataLoader, list_data_collate
from monai.networks.nets import UNet
from monai.losses import DiceFocalLoss
from monai.metrics import DiceMetric
from monai.inferers import sliding_window_inference


def main():
    # =========================================================================
    # –ù–ê–°–¢–†–û–ô–ö–ò –ü–£–¢–ï–ô
    # =========================================================================
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    DATA_DIR = os.path.join(BASE_DIR, "data")           # subset'—ã –≤–Ω—É—Ç—Ä–∏ data/
    MASK_DIR = os.path.join(BASE_DIR, "masks")           # –º–∞—Å–∫–∏ —É–∑–µ–ª–∫–æ–≤
    MODEL_SAVE_PATH = os.path.join(BASE_DIR, "luna16_unet.pth")

    LEARNING_RATE = 1e-4
    VAL_INTERVAL = 2    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö
    SAVE_INTERVAL = 10  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö

    # =========================================================================
    # –£–°–¢–†–û–ô–°–¢–í–û ‚Äî CUDA –ø–µ—Ä–≤—ã–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
    # =========================================================================
    if not torch.cuda.is_available():
        print("‚ö†  CUDA –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Ä–∞–±–æ—Ç–∞–µ–º –Ω–∞ CPU (–æ–±–ª–µ–≥—á—ë–Ω–Ω—ã–π —Ä–µ–∂–∏–º)")
        device = torch.device("cpu")
        num_gpus = 0
        MAX_EPOCHS = 3
        BATCH_SIZE = 1
        ACCUM_STEPS = 1
        PATCH_SIZE = (64, 64, 64)
        NUM_SAMPLES = 2
        NUM_WORKERS = 0
        CHANNELS = (16, 32, 64, 128)
        STRIDES = (2, 2, 2)
    else:
        device = torch.device("cuda")
        num_gpus = torch.cuda.device_count()
        torch.backends.cudnn.benchmark = True
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–±–æ –≤—Å–µ—Ö GPU
        total_gpu_mem = 0.0
        for i in range(num_gpus):
            name = torch.cuda.get_device_name(i)
            mem = torch.cuda.get_device_properties(i).total_memory / (1024 ** 3)
            total_gpu_mem += mem
            print(f"‚úì  GPU {i}: {name} ({mem:.1f} GB)")

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è –ø–æ–¥ –°–£–ú–ú–ê–†–ù–£–Æ GPU-–ø–∞–º—è—Ç—å
        if total_gpu_mem >= 20:     # 2x RTX 4070 = 24 GB / A100 / etc.
            MAX_EPOCHS = 80
            BATCH_SIZE = 3 * num_gpus   # 3 –Ω–∞ GPU ‚Äî ~8-9–ì–ë –∏–∑ 11.6–ì–ë, —Å –∑–∞–ø–∞—Å–æ–º
            ACCUM_STEPS = 1             # –ë–µ–∑ accumulation
            PATCH_SIZE = (128, 128, 128)
            NUM_SAMPLES = 6
            NUM_WORKERS = 4
            CHANNELS = (32, 64, 128, 256, 512)
            STRIDES = (2, 2, 2, 2)
        elif total_gpu_mem >= 8:
            MAX_EPOCHS = 60
            BATCH_SIZE = 2 * num_gpus
            ACCUM_STEPS = 1
            PATCH_SIZE = (96, 96, 96)
            NUM_SAMPLES = 6
            NUM_WORKERS = 4
            CHANNELS = (16, 32, 64, 128, 256)
            STRIDES = (2, 2, 2, 2)
        else:
            MAX_EPOCHS = 40
            BATCH_SIZE = 1 * num_gpus
            ACCUM_STEPS = 1
            PATCH_SIZE = (64, 64, 64)
            NUM_SAMPLES = 2
            NUM_WORKERS = 4
            CHANNELS = (16, 32, 64, 128)
            STRIDES = (2, 2, 2)

    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device} (GPU: {num_gpus})")
    print(f"–ü–∞—Ç—á–∏: {PATCH_SIZE}, Batch: {BATCH_SIZE}x{ACCUM_STEPS}accum={BATCH_SIZE*ACCUM_STEPS}eff, –≠–ø–æ—Ö–∏: {MAX_EPOCHS}")

    # =========================================================================
    # –°–ë–û–† –î–ê–ù–ù–´–• ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –≤—Å–µ—Ö subset* –ø–∞–ø–æ–∫ –≤ data/
    # =========================================================================
    if not os.path.isdir(DATA_DIR):
        print(f"–û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞ {DATA_DIR}")
        return

    subset_dirs = sorted([
        os.path.join(DATA_DIR, d) for d in os.listdir(DATA_DIR)
        if d.startswith("subset") and os.path.isdir(os.path.join(DATA_DIR, d))
    ])
    print(f"–ù–∞–π–¥–µ–Ω–æ subset-–ø–∞–ø–æ–∫: {len(subset_dirs)} ‚Üí "
          f"{[os.path.basename(d) for d in subset_dirs]}")

    data_dicts = []
    for sdir in subset_dirs:
        images = sorted(glob.glob(os.path.join(sdir, "*.mhd")))
        for img_path in images:
            uid = os.path.basename(img_path).replace(".mhd", "")
            mask_path = os.path.join(MASK_DIR, f"{uid}_mask.mhd")
            if os.path.exists(mask_path):
                # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Å–∫–∞–Ω—ã —Å —É–∑–µ–ª–∫–∞–º–∏ (foreground > 0)
                mask_img = sitk.ReadImage(mask_path)
                mask_arr = sitk.GetArrayFromImage(mask_img)
                if mask_arr.max() > 0:
                    data_dicts.append({"image": img_path, "label": mask_path})

    print(f"–°–∫–∞–Ω–æ–≤ —Å —É–∑–µ–ª–∫–∞–º–∏: {len(data_dicts)}")

    if not data_dicts:
        print("–û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–∫–∞–Ω–æ–≤ —Å —É–∑–µ–ª–∫–∞–º–∏!")
        print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏: python prepare_masks.py")
        return

    np.random.seed(42)
    np.random.shuffle(data_dicts)

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: 80% train / 20% validation
    split = max(1, int(len(data_dicts) * 0.8))
    train_dicts = data_dicts[:split]
    val_dicts = data_dicts[split:]
    print(f"  Train: {len(train_dicts)}, Val: {len(val_dicts)}")

    # =========================================================================
    # –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò
    # =========================================================================
    train_transforms = Compose([
        LoadImaged(keys=["image", "label"], reader="ITKReader"),
        EnsureChannelFirstd(keys=["image", "label"]),

        # –ò–∑–æ—Ç—Ä–æ–ø–Ω—ã–π —Ä–µ—Å–∞–º–ø–ª–∏–Ω–≥ 1–º–º ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ –ø—Ä–∏ —Ä–∞–∑–Ω–æ–º slice thickness
        Spacingd(keys=["image", "label"], pixdim=(1.0, 1.0, 1.0),
                 mode=("bilinear", "nearest")),

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ö–¢ Hounsfield Units ‚Üí [0, 1]
        ScaleIntensityRanged(
            keys=["image"],
            a_min=-1000, a_max=400,
            b_min=0.0, b_max=1.0,
            clip=True,
        ),

        # –ü–∞–¥–¥–∏–Ω–≥ –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –ø–∞—Ç—á–∞ (–µ—Å–ª–∏ —Å–∫–∞–Ω –º–µ–Ω—å—à–µ)
        SpatialPadd(keys=["image", "label"], spatial_size=PATCH_SIZE),

        # –í—ã—Ä–µ–∑–∞–µ–º 3D-–ø–∞—Ç—á–∏: pos=3/neg=1 ‚Äî –∞–∫—Ü–µ–Ω—Ç –Ω–∞ —É–∑–µ–ª–∫–∏
        RandCropByPosNegLabeld(
            keys=["image", "label"],
            label_key="label",
            spatial_size=PATCH_SIZE,
            pos=3, neg=1,
            num_samples=NUM_SAMPLES,
            image_key="image",
            image_threshold=0,
            allow_smaller=True,
        ),

        # –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),
        RandRotate90d(keys=["image", "label"], prob=0.5, max_k=3),

        # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ image)
        RandGaussianNoised(keys=["image"], prob=0.3, mean=0.0, std=0.05),
        RandScaleIntensityd(keys=["image"], factors=0.1, prob=0.3),
        RandShiftIntensityd(keys=["image"], offsets=0.1, prob=0.3),
    ])

    val_transforms = Compose([
        LoadImaged(keys=["image", "label"], reader="ITKReader"),
        EnsureChannelFirstd(keys=["image", "label"]),
        Spacingd(keys=["image", "label"], pixdim=(1.0, 1.0, 1.0),
                 mode=("bilinear", "nearest")),
        ScaleIntensityRanged(
            keys=["image"],
            a_min=-1000, a_max=400,
            b_min=0.0, b_max=1.0,
            clip=True,
        ),
    ])

    # =========================================================================
    # –î–ê–¢–ê–°–ï–¢–´ –ò –õ–û–ê–î–ï–†–´ ‚Äî CacheDataset –∫—ç—à–∏—Ä—É–µ—Ç —Å–Ω–∏–º–∫–∏ –≤ RAM
    # =========================================================================
    print("–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ RAM (–ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç)...")
    train_ds = CacheDataset(
        data=train_dicts, transform=train_transforms,
        cache_rate=0.3, num_workers=NUM_WORKERS,
    )
    val_ds = CacheDataset(
        data=val_dicts, transform=val_transforms,
        cache_rate=0.5, num_workers=NUM_WORKERS,
    )

    train_loader = DataLoader(
        train_ds,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=NUM_WORKERS,
        collate_fn=list_data_collate,
        pin_memory=torch.cuda.is_available(),
        persistent_workers=(NUM_WORKERS > 0),
        prefetch_factor=3 if NUM_WORKERS > 0 else None,
    )
    val_loader = DataLoader(
        val_ds,
        batch_size=1,
        num_workers=NUM_WORKERS,
        pin_memory=torch.cuda.is_available(),
        persistent_workers=(NUM_WORKERS > 0),
        prefetch_factor=3 if NUM_WORKERS > 0 else None,
    )

    # =========================================================================
    # –ú–û–î–ï–õ–¨ ‚Äî 3D U-Net (–Ω–∞ CUDA)
    # =========================================================================
    model = UNet(
        spatial_dims=3,
        in_channels=1,
        out_channels=2,           # –§–æ–Ω + –£–∑–µ–ª–æ–∫
        channels=CHANNELS,
        strides=STRIDES,
        num_res_units=2,
        dropout=0.1,
    ).to(device)

    total_params = sum(p.numel() for p in model.parameters())
    print(f"–ú–æ–¥–µ–ª—å: 3D U-Net, –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")

    # Multi-GPU: DataParallel
    if torch.cuda.is_available() and num_gpus > 1:
        model = nn.DataParallel(model)
        print(f"‚úì  DataParallel: –º–æ–¥–µ–ª—å –Ω–∞ {num_gpus} GPU")

    # Loss ‚Äî DiceFocalLoss: Dice –¥–ª—è –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è + Focal –¥–ª—è –º–µ–ª–∫–∏—Ö —É–∑–µ–ª–∫–æ–≤
    loss_function = DiceFocalLoss(
        to_onehot_y=True, softmax=True,
        include_background=False,
        gamma=2.0,
        lambda_dice=1.0,
        lambda_focal=2.0,   # –£—Å–∏–ª–µ–Ω–Ω—ã–π Focal –¥–ª—è —Ä–µ–¥–∫–æ–≥–æ foreground
    )
    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE * max(num_gpus, 1), weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCHS)
    dice_metric = DiceMetric(include_background=False, reduction="mean")

    # AMP (Mixed Precision) ‚Äî —É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ GPU
    use_amp = torch.cuda.is_available()
    scaler = torch.amp.GradScaler("cuda", enabled=use_amp)

    # =========================================================================
    # –¶–ò–ö–õ –û–ë–£–ß–ï–ù–ò–Ø
    # =========================================================================
    best_metric = -1.0

    print(f"\n{'='*60}")
    print(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ: {MAX_EPOCHS} —ç–ø–æ—Ö")
    print(f"–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞–∂–¥—ã–µ {VAL_INTERVAL} —ç–ø–æ—Ö")
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ {SAVE_INTERVAL} —ç–ø–æ—Ö")
    print(f"Mixed Precision (AMP): {'–î–∞' if use_amp else '–ù–µ—Ç'}")
    print(f"{'='*60}\n")

    total_start = time.time()

    for epoch in range(MAX_EPOCHS):
        epoch_start = time.time()
        elapsed_total = time.time() - total_start
        if epoch > 0:
            avg_epoch_time = elapsed_total / epoch
            eta = avg_epoch_time * (MAX_EPOCHS - epoch)
            eta_str = time.strftime('%H:%M:%S', time.gmtime(eta))
        else:
            eta_str = '??:??:??'

        print(f"\n{'='*60}")
        print(f"  –≠–ø–æ—Ö–∞ {epoch + 1}/{MAX_EPOCHS}  |  "
              f"–ü—Ä–æ—à–ª–æ: {time.strftime('%H:%M:%S', time.gmtime(elapsed_total))}  |  "
              f"ETA: {eta_str}")
        print(f"{'='*60}")

        # === TRAIN ===
        model.train()
        epoch_loss = 0.0
        step = 0

        optimizer.zero_grad(set_to_none=True)
        train_pbar = tqdm(train_loader, desc=f"[Train {epoch+1}/{MAX_EPOCHS}]",
                          unit="batch", leave=True, dynamic_ncols=True)
        for batch_data in train_pbar:
            step += 1
            inputs = batch_data["image"].to(device, non_blocking=True)
            labels = batch_data["label"].to(device, non_blocking=True)

            with torch.amp.autocast("cuda", enabled=use_amp):
                outputs = model(inputs)
                loss = loss_function(outputs, labels)
                loss = loss / ACCUM_STEPS  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è gradient accumulation

            scaler.scale(loss).backward()

            if step % ACCUM_STEPS == 0:
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad(set_to_none=True)

            epoch_loss += loss.item() * ACCUM_STEPS  # –†–µ–∞–ª—å–Ω—ã–π loss (–±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
            avg_so_far = epoch_loss / step
            train_pbar.set_postfix(loss=f"{loss.item()*ACCUM_STEPS:.4f}", avg=f"{avg_so_far:.4f}")

        # Flush –æ—Å—Ç–∞—Ç–∫–∞ gradient accumulation
        if step % ACCUM_STEPS != 0:
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad(set_to_none=True)

        avg_loss = epoch_loss / max(step, 1)
        scheduler.step()
        lr_now = optimizer.param_groups[0]['lr']

        # === VALIDATION (–∫–∞–∂–¥—ã–µ VAL_INTERVAL —ç–ø–æ—Ö) ===
        metric_val = -1.0
        if (epoch + 1) % VAL_INTERVAL == 0 or (epoch + 1) == MAX_EPOCHS:
            model.eval()
            raw_model = model.module if hasattr(model, 'module') else model
            with torch.no_grad():
                val_pbar = tqdm(val_loader, desc=f"[Val   {epoch+1}/{MAX_EPOCHS}]",
                                unit="scan", leave=True, dynamic_ncols=True)
                for val_data in val_pbar:
                    val_inputs = val_data["image"].to(device, non_blocking=True)
                    val_labels = val_data["label"].to(device, non_blocking=True)

                    with torch.amp.autocast("cuda", enabled=use_amp):
                        val_outputs = sliding_window_inference(
                            val_inputs, PATCH_SIZE, sw_batch_size=4, predictor=raw_model,
                        )

                    # One-hot –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è DiceMetric
                    val_pred = torch.argmax(val_outputs, dim=1, keepdim=True)
                    num_classes = val_outputs.shape[1]
                    val_pred_onehot = torch.nn.functional.one_hot(
                        val_pred.squeeze(1).long(), num_classes
                    ).permute(0, 4, 1, 2, 3).float()
                    val_labels_onehot = torch.nn.functional.one_hot(
                        val_labels.squeeze(1).long(), num_classes
                    ).permute(0, 4, 1, 2, 3).float()
                    dice_metric(y_pred=val_pred_onehot, y=val_labels_onehot)

                metric_val = dice_metric.aggregate().item()
                dice_metric.reset()

            elapsed = time.time() - epoch_start
            print(f"\n  >> –≠–ø–æ—Ö–∞ {epoch+1}/{MAX_EPOCHS}: "
                  f"Loss={avg_loss:.4f} | Dice={metric_val:.4f} | "
                  f"LR={lr_now:.2e} | –í—Ä–µ–º—è: {elapsed:.1f}—Å")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ Dice
            if metric_val > best_metric:
                best_metric = metric_val
                state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()
                torch.save({
                    "epoch": epoch + 1,
                    "model_state_dict": state_dict,
                    "optimizer_state_dict": optimizer.state_dict(),
                    "best_dice": best_metric,
                    "loss": avg_loss,
                }, MODEL_SAVE_PATH)
                print(f"  ‚òÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (Dice: {best_metric:.4f})")
        else:
            elapsed = time.time() - epoch_start
            print(f"\n  >> –≠–ø–æ—Ö–∞ {epoch+1}/{MAX_EPOCHS}: "
                  f"Loss={avg_loss:.4f} | Val: —Å–ª–µ–¥—É—é—â–∞—è –Ω–∞ —ç–ø. {((epoch+1)//VAL_INTERVAL+1)*VAL_INTERVAL} | "
                  f"LR={lr_now:.2e} | –í—Ä–µ–º—è: {elapsed:.1f}—Å")

        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
        if (epoch + 1) % SAVE_INTERVAL == 0:
            state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()
            save_path = MODEL_SAVE_PATH.replace(".pth", f"_ep{epoch+1}.pth")
            torch.save({
                "epoch": epoch + 1,
                "model_state_dict": state_dict,
                "optimizer_state_dict": optimizer.state_dict(),
                "loss": avg_loss,
                "dice": metric_val,
            }, save_path)
            print(f"  üìÅ –ß–µ–∫–ø–æ–∏–Ω—Ç: {os.path.basename(save_path)}")

        # –û—á–∏—Å—Ç–∫–∞ GPU-–∫—ç—à–∞
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    # =========================================================================
    # –ò–¢–û–ì–ò
    # =========================================================================
    print(f"\n{'='*60}")
    print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"–õ—É—á—à–∏–π Dice –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {best_metric:.4f}")
    print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {MODEL_SAVE_PATH}")

    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            peak_mem = torch.cuda.max_memory_allocated(i) / (1024 ** 3)
            print(f"–ü–∏–∫ GPU {i} –ø–∞–º—è—Ç–∏: {peak_mem:.2f} GB")

    print(f"{'='*60}")


if __name__ == "__main__":
    main()
